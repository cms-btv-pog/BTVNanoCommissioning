import psutil
import os
from tqdm import tqdm
import uproot
import warnings
import argparse
import glob
import matplotlib.pyplot as plt
from concurrent.futures import ThreadPoolExecutor, as_completed
import pandas as pd
import numpy as np
import seaborn as sns
import awkward as ak
from BTVNanoCommissioning.helpers.definitions import definitions_dict
from BTVNanoCommissioning.helpers.definitions import disc_list


# Suppress the specific FutureWarning from uproot
warnings.filterwarnings("ignore", category=FutureWarning, module="uproot")
warnings.filterwarnings("ignore", category=FutureWarning, module="seaborn")


filtered_names = [
    name for name in disc_list if name.endswith("B") and not name.endswith("CvB")
]


def is_within_range(array, min_value, max_value):
    """Check if all values in the array are within the specified range."""
    return ak.all((array >= min_value) & (array <= max_value))


def load_single_file(
    file_path,
    base_dir,
    chunk_size=100000,
    temp_subdir="temp_data",
    limit_inputs=False,
    limit_outputs=False,
    SMu=False,
    flavour_split=False,
):
    temp_dir = os.path.join(base_dir, temp_subdir)
    if not os.path.exists(temp_dir):
        os.makedirs(temp_dir, exist_ok=True)

    with uproot.open(file_path) as file:
        if "Events" not in file:
            print(f"Skipping file without 'Events' key: {file_path}")
            return

        tree = file["Events"]
        if tree.num_entries == 0:
            print(f"Skipping empty file: {file_path}")
            return

        # Apply limit_inputs filter
        if limit_inputs:
            filtered_definitions_dict = {
                k: v
                for k, v in definitions_dict.items()
                if any(sub in k for sub in ["Npfcan", "Cpfcan", "sv"])
                and k.endswith("_0")
                or not any(sub in k for sub in ["Npfcan", "Cpfcan", "sv"])
            }
        else:
            filtered_definitions_dict = definitions_dict

        # Initialize filtered_names
        filtered_names = [
            name
            for name in disc_list
            if name.endswith("B") and not name.endswith("CvB")
        ]

        # Apply limit_outputs filter
        if limit_outputs:
            filtered_names = [
                name
                for name in filtered_names
                if name.endswith("B")
                and "Neg" not in name
                and "btagPNetProbB" not in name
            ]

        # Filter branches to include only those with 'SelJets' in their name, containing keys from filtered_definitions_dict, and matching filtered_names
        branches = [
            branch
            for branch in tree.keys()
            if "MuonJet" in branch
            and (
                any(key in branch for key in filtered_definitions_dict.keys())
                or any(name in branch for name in filtered_names)
            )
        ]

        if limit_outputs:
            branches = [
                branch
                for branch in branches
                if not any(name in branch for name in filtered_names)
                or any(
                    name in branch for name in filtered_names if branch.endswith("B")
                )
            ]

        # Include branches that have 'SMu' in their name if the SMu flag is True
        if SMu:
            smu_branches = [branch for branch in tree.keys() if "SoftMuon" in branch]
            smu_branches.append("MuonJet_muEF")
            if limit_inputs:
                smu_branches = [
                    "SoftMuon_tunepRelPt",
                    "SoftMuon_pfRelIso03_chg",
                    "SoftMuon_eta",
                    "SoftMuon_phi",
                    "SoftMuon_jetPtRelv2",
                    "SoftMuon_dxy",
                    "SoftMuon_dxyErr",
                    "SoftMuon_jetRelIso",
                    "SoftMuon_sip3d",
                    "SoftMuon_dzErr",
                    "SoftMuon_pfRelIso04_all",
                    "SoftMuon_ip3d",
                    "SoftMuon_pt",
                    "SoftMuon_ptErr",
                    "SoftMuon_tkRelIso",
                    "SoftMuon_dz",
                    "SoftMuon_pfRelIso03_all",
                    "MuonJet_muEF",
                    "SoftMuon_charge",
                ]
            branches.extend(smu_branches)
            branches = list(set(branches))  # Remove duplicates

        # Include the flavour column if flavour_split is enabled
        if flavour_split:
            branches.append("MuonJet_hadronFlavour")

        # Extract manual ranges for x and y columns if they don't start with SelJet_ or SMu_
        x_limits_dict = {}
        for x_col in branches:
            if not x_col.startswith(("SelJet_", "SoftMuon_", "MuonJet_")):
                x_limits = definitions_dict.get(x_col, {}).get("manual_ranges", None)
            else:
                x_col_str = (
                    x_col.lstrip("SelJet_").lstrip("SoftMuon_").lstrip("MuonJet_")
                )
                x_limits = definitions_dict.get(x_col_str, {}).get(
                    "manual_ranges", None
                )

            x_limits_dict[x_col] = x_limits

        for i, data_chunk in enumerate(
            tree.iterate(branches, library="pd", step_size=chunk_size)
        ):
            if isinstance(data_chunk, tuple):
                data_chunk = data_chunk[0]  # Extract the DataFrame from the tuple

            # Filter the data based on MuJet_Cpfcan_ptrel_0
            ###data_chunk = data_chunk[data_chunk['MuJet_DeepJet_Cpfcan_ptrel_0'] >= -20]

            # Filter the data based on x_limits
            for col, limits in x_limits_dict.items():
                if limits is not None:
                    min_value, max_value = limits
                    data_chunk = data_chunk[
                        (data_chunk[col] >= min_value) & (data_chunk[col] <= max_value)
                    ]
            temp_file_path = os.path.join(
                temp_dir, f"{os.path.basename(file_path)}_chunk_{i}.parquet"
            )
            data_chunk.to_parquet(temp_file_path)


def inspect_first_file(
    file_path, limit_inputs=False, limit_outputs=False, SMu=False, flavour_split=False
):
    with uproot.open(file_path) as file:
        print(f"Inspecting file: {file_path}")
        print("Keys:", file.keys())
        if "Events" in file:
            tree = file["Events"]
            print("Number of entries in 'Events':", tree.num_entries)

            # Apply limit_inputs filter
            if limit_inputs:
                filtered_definitions_dict = {
                    k: v
                    for k, v in definitions_dict.items()
                    if any(sub in k for sub in ["Npfcan", "Cpfcan", "sv"])
                    and k.endswith("_0")
                    or not any(sub in k for sub in ["Npfcan", "Cpfcan", "sv"])
                }
            else:
                filtered_definitions_dict = definitions_dict

            # Initialize filtered_names
            filtered_names = [
                name
                for name in disc_list
                if name.endswith("B") and not name.endswith("CvB")
            ]

            # Apply limit_outputs filter
            if limit_outputs:
                filtered_names = [
                    name
                    for name in filtered_names
                    if name.endswith("B")
                    and "Neg" not in name
                    and "btagPNetProbB" not in name
                ]

            print(tree.keys())
            # Filter branches to include only those with 'SelJets' in their name, containing keys from definitions_dict, and matching filtered_names

            branches = [
                branch
                for branch in tree.keys()
                if "MuJet" in branch
                and (
                    any(key in branch for key in filtered_definitions_dict.keys())
                    or any(name in branch for name in filtered_names)
                )
            ]
            if limit_outputs:
                branches = [
                    branch
                    for branch in branches
                    if not any(name in branch for name in filtered_names)
                    or any(
                        name in branch
                        for name in filtered_names
                        if branch.endswith(name)
                    )
                ]
            print("Filtered Branches:", branches)
            print(len(branches))
            if SMu:
                smu_branches = [
                    branch for branch in tree.keys() if "SoftMuon" in branch
                ]
                smu_branches.append("MuonJet_muEF")
                print(smu_branches)
                if limit_inputs:
                    smu_branches = [
                        "SoftMuon_tunepRelPt",
                        "SoftMuon_pfRelIso03_chg",
                        "SoftMuon_eta",
                        "SoftMuon_phi",
                        "SoftMuon_jetPtRelv2",
                        "SoftMuon_dxy",
                        "SoftMuon_dxyErr",
                        "SoftMuon_jetRelIso",
                        "SoftMuon_sip3d",
                        "SoftMuon_dzErr",
                        "SoftMuon_pfRelIso04_all",
                        "SoftMuon_ip3d",
                        "SoftMuon_pt",
                        "SoftMuon_ptErr",
                        "SoftMuon_tkRelIso",
                        "SoftMuon_dz",
                        "SoftMuon_pfRelIso03_all",
                        "MuonJet_muEF",
                        "SoftMuon_charge",
                    ]

                branches.extend(smu_branches)
                branches = list(set(branches))  # Remove duplicates
                print("Branches with SMu:", smu_branches)

            # Include the flavour column if flavour_split is enabled
            if flavour_split:
                branches.append("MuonJet_hadronFlavour")

            print("Branches:", branches)

            # Find branches that contain any of the keys from definitions_dict
            matching_keys = [
                branch
                for branch in branches
                if any(key in branch for key in definitions_dict.keys())
            ]
            print("Branches containing keys from definitions_dict:", matching_keys)
            print(len(matching_keys))

            matching_keys = [
                branch
                for branch in branches
                if any(name in branch for name in filtered_names)
            ]
            print("Branches containing keys from definitions_dict:", matching_keys)
            print(len(matching_keys))

            # Print the filtered names
            print("Filtered Names:", filtered_names)

            # Extract manual ranges for x and y columns if they don't start with SelJet_ or SMu_
            x_limits_dict = {}
            for x_col in branches:
                if not x_col.startswith(("SelJet_", "SoftMuon_", "MuonJet_")):
                    x_limits = definitions_dict.get(x_col, {}).get(
                        "manual_ranges", None
                    )
                else:
                    x_col_str = (
                        x_col.lstrip("SelJet_").lstrip("SoftMuon_").lstrip("MuonJet_")
                    )
                    x_limits = definitions_dict.get(x_col_str, {}).get(
                        "manual_ranges", None
                    )

                x_limits_dict[x_col] = x_limits
                # Debugging prints
                # print(f"x_col: {x_col}")
                # print(f"Manual ranges for {x_col}: {x_limits}")

            # Load the first chunk to inspect memory usage
            data_chunk = next(tree.iterate(branches, library="pd", step_size=100000))
            if isinstance(data_chunk, tuple):
                data_chunk = data_chunk[0]  # Extract the DataFrame from the tuple

            # Filter the data based on x_limits
            for col, limits in x_limits_dict.items():
                if limits is not None:
                    min_value, max_value = limits
                    data_chunk = data_chunk[
                        (data_chunk[col] >= min_value) & (data_chunk[col] <= max_value)
                    ]

            memory_usage = data_chunk.memory_usage(deep=True).sum()
            print(
                f"Memory usage of the first DataFrame chunk: {memory_usage / (1024 ** 2):.2f} MB"
            )
        else:
            print("'Events' key not found in the file.")


def load_data(
    file_paths,
    base_dir,
    batch_size=2,
    temp_subdir="temp_data",
    output_subdir="parquet_data",
    max_files=None,
    limit_inputs=False,
    limit_outputs=False,
    SMu=False,
    flavour_split=False,
):
    # Step 1: Inspect the nominal folder
    nominal_folder = os.path.join(base_dir, "nominal")
    nominal_subfolders = {}
    if os.path.exists(nominal_folder):
        for subfolder in os.listdir(nominal_folder):
            subfolder_path = os.path.join(nominal_folder, subfolder)
            if os.path.isdir(subfolder_path):
                # Count the number of .root files in the subfolder
                root_files = [
                    f for f in os.listdir(subfolder_path) if f.endswith(".root")
                ]
                root_file_count = len(root_files)
                # Print the count of .root files
                print(
                    f"Subfolder: {subfolder}, Number of .root files: {root_file_count}"
                )
                # Store the subfolder path for later use
                nominal_subfolders[subfolder] = subfolder_path

    if max_files is not None:
        file_paths = file_paths[:max_files]

    output_dir = os.path.join(base_dir, output_subdir)
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    with ThreadPoolExecutor(max_workers=batch_size) as executor:
        futures = [
            executor.submit(
                load_single_file,
                file_path,
                base_dir,
                temp_subdir=temp_subdir,
                limit_inputs=limit_inputs,
                limit_outputs=limit_outputs,
                SMu=SMu,
                flavour_split=flavour_split,
            )
            for file_path in file_paths
        ]
        for future in tqdm(
            as_completed(futures), total=len(futures), desc="Processing files"
        ):
            future.result()  # Ensure any exceptions are raised

    combined_data = {}
    temp_files = glob.glob(os.path.join(base_dir, temp_subdir, "*.parquet"))
    print(f"Temporary files found: {len(temp_files)}")  # Debugging line
    event_counts = []
    for temp_file in temp_files:
        df = pd.read_parquet(temp_file)
        key = os.path.basename(temp_file).replace(".parquet", "")
        combined_data[key] = df  # Store the DataFrame directly
        event_counts.append((key, len(df)))  # Store the number of events and the key

    # Define ranking factors for each subfolder
    ### FIXME: sumw has to change, whenever you run a different set. Pay attention!!!
    ### FIXME: The former factor is the xs, the second - sumw!
    ranking_factors = {
        "QCD_PT-15to20_MuEnrichedPt5_TuneCP5_13p6TeV_pythia8": 295600 / 142083,
        "QCD_PT-20to30_MuEnrichedPt5_TuneCP5_13p6TeV_pythia8": 2689000 / 5926,
        "QCD_PT-30to50_MuEnrichedPt5_TuneCP5_13p6TeV_pythia8": 1442000 / 339153,
        "QCD_PT-50to80_MuEnrichedPt5_TuneCP5_13p6TeV_pythia8": 405800 / 94942,
        "QCD_PT-80to120_MuEnrichedPt5_TuneCP5_13p6TeV_pythia8": 96060 / 488561,
        "QCD_PT-120to170_MuEnrichedPt5_TuneCP5_13p6TeV_pythia8": 23230 / 210233,
        "QCD_PT-1700to300_MuEnrichedPt5_TuneCP5_13p6TeV_pythia8": 7763 / 216617,
        "QCD_PT-300to470_MuEnrichedPt5_TuneCP5_13p6TeV_pythia8": 701.4 / 196409,
        "QCD_PT-470to600_MuEnrichedPt5_TuneCP5_13p6TeV_pythia8": 68.24 / 254794,
        "QCD_PT-600to800_MuEnrichedPt5_TuneCP5_13p6TeV_pythia8": 21.23 / 34096,
        "QCD_PT-800to1000_MuEnrichedPt5_TuneCP5_13p6TeV_pythia8": 3.9 / 155007,
        "QCD_PT-1000_MuEnrichedPt5_TuneCP5_13p6TeV_pythia8": 1.323 / 237819,
    }

    # Sort event counts by the number of events in descending order
    event_counts.sort(key=lambda x: x[1], reverse=True)

    # Display the ranking
    print("Ranking by number of events:")
    for rank, (key, count) in enumerate(event_counts, start=1):
        # Strip the _chunk_0 suffix
        stripped_key = key.replace("_chunk_0", "")
        # Determine the parent subfolder
        parent_subfolder = None
        for subfolder, path in nominal_subfolders.items():
            if stripped_key in os.listdir(path):
                parent_subfolder = subfolder
                break
        print(
            f"{rank}. File: {key}, Number of events: {count}, Parent subfolder: {parent_subfolder}"
        )

    # Calculate weighted event counts
    weighted_event_counts = []
    for key, count in event_counts:
        stripped_key = key.replace("_chunk_0", "")
        parent_subfolder = None
        for subfolder, path in nominal_subfolders.items():
            if stripped_key in os.listdir(path):
                parent_subfolder = subfolder
                break
        factor = ranking_factors.get(
            parent_subfolder, 1.0
        )  # Default factor is 1.0 if not specified
        weighted_count = count * factor
        weighted_event_counts.append((key, weighted_count, parent_subfolder))

    # Sort weighted event counts by the weighted number of events in descending order
    weighted_event_counts.sort(key=lambda x: x[1], reverse=True)

    # Display the ranking
    ### Ranking done by the yields: from the highest to the lowest
    print("Ranking by weighted number of events:")
    for rank, (key, weighted_count, parent_subfolder) in enumerate(
        weighted_event_counts, start=1
    ):
        print(
            f"{rank}. File: {key}, Weighted number of events: {weighted_count}, Parent subfolder: {parent_subfolder}"
        )

    print(f"Combined data keys: {list(combined_data.keys())}")  # Debugging line
    return combined_data


variables_to_zoom = {
    "MuonJet_DeepCSV_flightDistance2dSig": [2, 4],
    "MuonJet_DeepCSV_flightDistance2dVal": [0, 0.4],
    "MuonJet_DeepCSV_flightDistance3dSig": [1, 10],
    "MuonJet_DeepCSV_flightDistance3dVal": [0, 0.5],
    "MuonJet_DeepCSV_jetNSelectedTracks": [5, 12],
    "MuonJet_DeepCSV_trackJetPt": [25, 60],
    "MuonJet_DeepCSV_trackSip2dSigAboveCharm": [0, 2],
    "MuonJet_DeepCSV_trackSip2dValAboveCharm": [0, 0.01],
    "MuonJet_DeepCSV_trackSip3dSigAboveCharm": [0, 2],
    "MuonJet_DeepCSV_trackSip3dValAboveCharm": [0, 0.01],
    "MuonJet_DeepCSV_trackSumJetDeltaR": [0, 0.03],
    "MuonJet_DeepCSV_vertexEnergyRatio": [0, 0.4],
    "MuonJet_DeepCSV_vertexJetDeltaR": [0, 0.07],
    "SoftMuon_ip3d": [0, 0.05],
    "SoftMuon_jetPtRelv2": [0, 1],
    "SoftMuon_jetRelIso": [0, 30],
    "SoftMuon_pfRelIso03_all": [0, 20],
    "SoftMuon_pfRelIso03_chg": [0, 20],
    "SoftMuon_pfRelIso04_all": [0, 20],
    "SoftMuon_sip3d": [0, 15],
}


# Function to print keys of definitions_dict
def print_definitions_keys():
    keys = definitions_dict.keys()
    print("Keys in definitions_dict:", keys)
    print(len(keys))


def plot_2d_histogram(
    data, x_col, y_col, output_dir, x_limits=None, y_limits=None, x_bins=50, y_bins=50
):
    plt.figure(figsize=(10, 8))
    hist = sns.histplot(
        data, x=x_col, y=y_col, bins=(x_bins, y_bins), pthresh=0.1, cmap="viridis"
    )

    if x_limits is not None:
        plt.xlim(x_limits)
    if y_limits is not None:
        plt.ylim(y_limits)

    plt.xlabel(x_col)
    plt.ylabel(y_col)
    plt.title(f"2D Histogram of {x_col} vs {y_col}")
    plt.colorbar(hist.collections[0], label="Counts")
    plt.grid(True)
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, f"{x_col}_vs_{y_col}.png"))
    plt.close()


def plot_all_histograms(
    data,
    definitions_dict,
    filtered_names,
    output_dir,
    include_smu=False,
    flavour_split=False,
    split_region_b=False,
    zoom=False,
):
    print("Data columns:", data.columns)
    print("Definitions dict keys:", definitions_dict.keys())
    print("Filtered names:", filtered_names)

    # Extend definitions_dict with SMu columns if include_smu is True
    if include_smu:
        smu_columns = [col for col in data.columns if "SMu" in col]
        for col in smu_columns:
            if col not in definitions_dict:
                definitions_dict[col] = col  # Add SMu columns to definitions_dict

    print("Definitions dict keys:", definitions_dict.keys())

    if flavour_split:
        flavour_column = "MuJet_hadronFlavour"

        flavour_groups = {
            "light": data[data[flavour_column] == 0],
            "charm": data[data[flavour_column] == 4],
            "bottom": data[data[flavour_column] == 5],
        }
        for flavour in flavour_groups.keys():
            flavour_data = flavour_groups[flavour]
            flavour_dir = os.path.join(output_dir, f"flavour_{flavour}")
            os.makedirs(flavour_dir, exist_ok=True)
            plot_histograms_for_data(
                flavour_data, definitions_dict, filtered_names, flavour_dir, zoom
            )

    elif split_region_b:
        deepflavb_column = "MuonJet_btagDeepFlavB"
        high_probB_data = data[data[deepflavb_column] > 0.5]
        low_probB_data = data[data[deepflavb_column] <= 0.5]

        high_probB_dir = os.path.join(output_dir, "high_probB")
        low_probB_dir = os.path.join(output_dir, "low_probB")

        os.makedirs(high_probB_dir, exist_ok=True)
        os.makedirs(low_probB_dir, exist_ok=True)

        plot_histograms_for_data(
            high_probB_data, definitions_dict, filtered_names, high_probB_dir, zoom
        )
        plot_histograms_for_data(
            low_probB_data, definitions_dict, filtered_names, low_probB_dir, zoom
        )

    else:
        plot_histograms_for_data(
            data, definitions_dict, filtered_names, output_dir, zoom
        )


def plot_histograms_for_data(
    data, definitions_dict, filtered_names, output_dir, zoom=False
):
    for input_col in definitions_dict.keys():
        for output_col in filtered_names:
            matching_input_cols = [col for col in data.columns if input_col in col]
            matching_output_cols = [col for col in data.columns if output_col in col]

            for x_col in matching_input_cols:
                for y_col in matching_output_cols:
                    print(f"Plotting {x_col} vs {y_col}")

                    # Extract manual ranges for x and y columns if they don't start with SelJet_ or SMu_
                    if not x_col.startswith(("SelJet_", "SMu_", "MuJet_")):
                        x_limits = definitions_dict.get(x_col, {}).get(
                            "manual_ranges", None
                        )
                        x_bins = definitions_dict.get(x_col, {}).get("bins", 50)
                    else:
                        x_col_str = (
                            x_col.lstrip("SelJet_").lstrip("SMu_").lstrip("MuJet_")
                        )
                        x_limits = definitions_dict.get(x_col_str, {}).get(
                            "manual_ranges", None
                        )
                        x_bins = definitions_dict.get(x_col_str, {}).get("bins", 50)

                    if not y_col.startswith(("SelJet_", "SMu_", "MuJet_")):
                        y_limits = definitions_dict.get(y_col, {}).get(
                            "manual_ranges", None
                        )
                        y_bins = definitions_dict.get(x_col, {}).get("bins", 50)
                    else:
                        y_col_str = (
                            y_col.lstrip("SelJet_").lstrip("SMu_").lstrip("MuJet_")
                        )
                        y_limits = definitions_dict.get(y_col_str, {}).get(
                            "manual_ranges", None
                        )
                        y_bins = definitions_dict.get(y_col_str, {}).get("bins", 50)

                    # Debugging prints
                    print(f"x_col: {x_col}, y_col: {y_col}")
                    print(
                        f"definitions_dict[{x_col}]: {definitions_dict.get(x_col, 'Not found')}"
                    )
                    print(
                        f"definitions_dict[{y_col}]: {definitions_dict.get(y_col, 'Not found')}"
                    )
                    print(f"Manual ranges for {x_col}: {x_limits}")
                    print(f"Manual ranges for {y_col}: {y_limits}")

                    print(f"Bin count for {x_col}: {x_bins}")
                    print(f"Bin count for {y_col}: {y_bins}")
                    # If zoom is active, create zoomed histograms
                    if zoom and x_col in variables_to_zoom:
                        zoomed_dir = os.path.join(output_dir, "zoomed_hists")
                        os.makedirs(zoomed_dir, exist_ok=True)

                        x_zoom = variables_to_zoom[x_col]
                        plot_2d_histogram(
                            data,
                            x_col,
                            y_col,
                            zoomed_dir,
                            x_limits=x_zoom,
                            y_limits=y_limits,
                            x_bins=40,
                            y_bins=y_bins,
                        )

                    plot_2d_histogram(
                        data,
                        x_col,
                        y_col,
                        output_dir,
                        x_limits=x_limits,
                        y_limits=y_limits,
                        x_bins=x_bins,
                        y_bins=y_bins,
                    )


def main():
    parser = argparse.ArgumentParser(description="Generate correlation plots.")
    parser.add_argument(
        "folder", type=str, help="The folder containing the data files."
    )
    parser.add_argument(
        "--max_files",
        type=int,
        default=None,
        help="Maximum number of files to process.",
    )
    parser.add_argument(
        "--limit_inputs",
        action="store_true",
        help="Limit inputs to variables with npf, cpf, sv and _0",
    )
    parser.add_argument(
        "--limit_outputs",
        action="store_true",
        help="Limit outputs to names ending with B and not containing Neg",
    )
    parser.add_argument(
        "--SMu", action="store_true", help="Include branches with SMu in their name"
    )
    parser.add_argument(
        "--flavour_split",
        action="store_true",
        help="Split correlations by hadron flavour",
    )
    parser.add_argument(
        "--split_region_b", action="store_true", help="Split correlations by region B"
    )
    parser.add_argument(
        "--zoom", action="store_true", help="Zoom in on the correlation plots"
    )
    args = parser.parse_args()

    data_file_paths = glob.glob(
        os.path.join(args.folder, "**", "*.root"), recursive=True
    )
    print(f"Data file paths: {data_file_paths}")  # Debugging line
    # print(data_file_paths)
    # print_definitions_keys()

    if data_file_paths:
        inspect_first_file(
            data_file_paths[0],
            limit_inputs=args.limit_inputs,
            limit_outputs=args.limit_outputs,
            SMu=args.SMu,
            flavour_split=args.flavour_split,
        )

    parquet_dir = os.path.join(args.folder, "parquet_data")
    histograms_dir = os.path.join(args.folder, "2D_histograms")
    os.makedirs(histograms_dir, exist_ok=True)

    data_dict = load_data(
        data_file_paths,
        args.folder,
        max_files=args.max_files,
        limit_inputs=args.limit_inputs,
        limit_outputs=args.limit_outputs,
        SMu=args.SMu,
        flavour_split=args.flavour_split,
    )

    # Concatenate all DataFrames if load_data returns a dictionary of DataFrames
    if isinstance(data_dict, dict):
        data = pd.concat(data_dict.values(), ignore_index=True)
    else:
        data = data_dict

    # Print data columns for debugging
    print("Data columns after loading and concatenation:", data.columns)

    # Plot 2D histograms of inputs vs outputs
    plot_all_histograms(
        data,
        definitions_dict,
        filtered_names,
        histograms_dir,
        include_smu=args.SMu,
        flavour_split=args.flavour_split,
        split_region_b=args.split_region_b,
        zoom=args.zoom,
    )


if __name__ == "__main__":
    main()
